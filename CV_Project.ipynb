{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465e0588",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Authors: Laurynas Varnas, Marco Gabriel, Nicolau Oliver Burwitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914865c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from bisect import bisect\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "from cv2.typing import MatLike\n",
    "from scipy.optimize import fsolve\n",
    "from sympy import Matrix, Symbol, lambdify\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95681a-65b7-4527-84aa-5508f3b934ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoReader:\n",
    "    def __init__(self, video_path: str | Path, max_count=-1) -> None:\n",
    "        self.count = max_count\n",
    "        self.video = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "        if not self.video.isOpened():\n",
    "            print(\"Error openning video file\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> MatLike:\n",
    "        _, frame = self.video.read()\n",
    "\n",
    "        if frame is None or self.count == 0:\n",
    "            self.video.release()\n",
    "            raise StopIteration\n",
    "\n",
    "        self.count -= 1\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa93da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of score tag\n",
    "# np.array([679 - 651, 960 - 320])\n",
    "\n",
    "\n",
    "# Return the score tag coordinates\n",
    "# TODO: reduce resolution of output score tag, automate detect resolution of sample image and score tag coordinates\n",
    "def extract_score_tag(frame: MatLike) -> MatLike:\n",
    "    width, height, _ = frame.shape\n",
    "    # Resolution of 'WSC\\ sample.png'\n",
    "    baseline_width, baseline_height = (720, 1280)\n",
    "\n",
    "    # Relevant rang minus one pixel border due to blurring spill\n",
    "    # Handpicked image coordinates of 'WSC\\ sample.png'\n",
    "    a_x, a_y = (651, 320)  # Upper left corner of score tag\n",
    "    b_x, b_y = (679, 960)  # Lower right corner of score tag\n",
    "\n",
    "    # Rescale coordinates to frame resolution\n",
    "    r_x = width / baseline_width  # width scaling ratio\n",
    "    r_y = height / baseline_height  # height scaling ratio\n",
    "    a_x, a_y = (int(np.ceil(a_x * r_x)), int(np.ceil(a_y * r_y)))\n",
    "    b_x, b_y = (int(np.floor(b_x * r_x)), int(np.floor(b_y * r_y)))\n",
    "\n",
    "    # Extract score tag\n",
    "    # print(a_x,a_y,b_x,b_y)\n",
    "    score_tag = frame[a_x:b_x, a_y:b_y]\n",
    "\n",
    "    return score_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f29a9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Resolution agnostic comparison of score tags\n",
    "# TODO: reduce the amount of pixels checked, uniform sparse sampling\n",
    "def compare_score_tag(baseline, sample, tolerance=0.15) -> bool:\n",
    "    baseline_width, baseline_height, _ = baseline.shape\n",
    "    sample_width, sample_height, _ = sample.shape\n",
    "\n",
    "    # Compute smallest resolution\n",
    "    width, height = (\n",
    "        min(baseline_width, sample_width),\n",
    "        min(baseline_height, sample_height),\n",
    "    )\n",
    "\n",
    "    # Resize inputs\n",
    "    baseline_small = cv2.resize(baseline, (height, width))\n",
    "    sample_small = cv2.resize(sample, (height, width))\n",
    "\n",
    "    # Compute abs diff and sum up as score\n",
    "    diff = cv2.absdiff(baseline_small, sample_small)\n",
    "    diff_score = np.sum(diff)\n",
    "\n",
    "    # Tolerance on error (max allowed score)\n",
    "    threshold = tolerance * (width * height * 3) * 255\n",
    "\n",
    "    return diff_score < threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd9378",
   "metadata": {},
   "source": [
    "# Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d75b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_lines(binary_img, rho_step=0.5, theta_step=0.5, num_lines=4):\n",
    "    \"\"\"\n",
    "    Hough line implementation\n",
    "    original source: https://github.com/alyssaq/hough_transform\n",
    "    \"\"\"\n",
    "    width, height = binary_img.shape\n",
    "    # Rho and Theta ranges\n",
    "    thetas = np.deg2rad(np.arange(-90, 90 - theta_step, theta_step))\n",
    "    diag_len = np.ceil(np.sqrt(width**2 + height**2))  # max_dist\n",
    "    rhos = np.arange(-diag_len, diag_len, rho_step)\n",
    "\n",
    "    # Cache some resuable values\n",
    "    cos_theta = np.cos(thetas)\n",
    "    sin_theta = np.sin(thetas)\n",
    "\n",
    "    # Hough accumulator array of theta vs rho\n",
    "    accumulator = np.zeros((len(rhos), len(thetas)))\n",
    "    # (row, col) indexes to edges\n",
    "    y_idxs, x_idxs = np.nonzero(binary_img)\n",
    "    # Vote in the hough accumulator\n",
    "    for i in range(len(x_idxs)):\n",
    "        x = x_idxs[i]\n",
    "        y = y_idxs[i]\n",
    "        for t_idx in range(len(thetas)):\n",
    "            # Calculate rho\n",
    "            rho = x * cos_theta[t_idx] + y * sin_theta[t_idx]\n",
    "            r_idx = bisect(\n",
    "                rhos, rho, hi=len(rhos) - 1\n",
    "            )  # which in rhos is the closest one\n",
    "            accumulator[r_idx, t_idx] += 1\n",
    "\n",
    "    # old_accumulator = np.copy(accumulator)\n",
    "\n",
    "    # Non maxima supression\n",
    "    # num_lines = 4 #Assumption on the number of lines we have\n",
    "    lines = []\n",
    "    for i in range(num_lines):\n",
    "        rho_max_i, theta_max_i = np.unravel_index(\n",
    "            np.argmax(accumulator), accumulator.shape\n",
    "        )\n",
    "        lines.append((rhos[rho_max_i], thetas[theta_max_i]))\n",
    "        r_window = (\n",
    "            20  # Assumption on the lines we want to detect having notably different rho\n",
    "        )\n",
    "        t_window = 20  # Lines we want to detect have different theta\n",
    "        for r_w in range(-r_window, r_window + 1):\n",
    "            r_w_mod = min(max((rho_max_i + r_w), 0), len(rhos))\n",
    "            for t_w in range(-t_window, t_window + 1):\n",
    "                t_w_mod = (theta_max_i + t_w) % len(thetas)\n",
    "                # Supress maxima in neibourhood\n",
    "                accumulator[r_w_mod, t_w_mod] = 0\n",
    "\n",
    "    # accumulator = np.absolute(old_accumulator - accumulator)\n",
    "\n",
    "    # Equalization and scaling for visualization\n",
    "    # accumulator = np.floor(accumulator*255/(np.max(accumulator))).astype(np.uint8)\n",
    "    # new_scale = np.flip(np.array(accumulator.shape) * 8)\n",
    "    # acc_img = cv2.resize(accumulator,new_scale)\n",
    "    # cv2.imshow('tmp', acc_img)\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8570379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_edges_detection(frame_BGR: MatLike) -> (MatLike, list):\n",
    "    \"\"\"\n",
    "    Function that detects the hardcoded green and brown colors\n",
    "    and computes the edges where the colors touch. It then\n",
    "    computes the most likely 4 straight lines that fit the edges\n",
    "    \"\"\"\n",
    "    width, height, _ = frame_BGR.shape\n",
    "\n",
    "    frame_HSV = cv2.cvtColor(frame_BGR, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # CV2 HSV ranges: Hue from 0 to 180, Staturation form 0 to 100, Value from 0 to 100\n",
    "\n",
    "    # Filter green color\n",
    "    # NOTE: Hard-coded green HSV value\n",
    "    GREEN_HSV_LOW = np.array([55, 100, 50])\n",
    "    GREEN_HSV_HIGH = np.array([65, 255, 220])\n",
    "    frame_green = cv2.inRange(frame_HSV, GREEN_HSV_LOW, GREEN_HSV_HIGH)\n",
    "\n",
    "    # Filter brown color\n",
    "    # NOTE: Hard-coded brown HSV value\n",
    "    BROWN_HSV_LOW = np.array([0, 0, 20])\n",
    "    BROWN_HSV_HIGH = np.array([5, 200, 150])\n",
    "    frame_brown_1 = cv2.inRange(frame_HSV, BROWN_HSV_LOW, BROWN_HSV_HIGH)\n",
    "\n",
    "    # NOTE: Hard-coded another brown HSV value\n",
    "    BROWN_HSV_LOW = np.array([130, 0, 20])\n",
    "    BROWN_HSV_HIGH = np.array([180, 200, 150])\n",
    "    frame_brown_2 = cv2.inRange(frame_HSV, BROWN_HSV_LOW, BROWN_HSV_HIGH)\n",
    "\n",
    "    frame_brown = cv2.bitwise_or(frame_brown_1, frame_brown_2)\n",
    "\n",
    "    # Noise filtering\n",
    "    # frame_green = cv2.morphologyEx(frame_green, cv2.MORPH_OPEN, kernel)\n",
    "    # frame_green = cv2.morphologyEx(frame_green, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Dilate green and brown so that they overlap\n",
    "    # NOTE: Hard-coded value\n",
    "    KERNEL_SMALL = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n",
    "    brown_dilate = cv2.dilate(frame_brown, KERNEL_SMALL)\n",
    "    KERNEL_VERY_SMALL = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
    "    green_dilate = cv2.dilate(frame_green, KERNEL_VERY_SMALL)\n",
    "\n",
    "    # Remove some balls from the green playing area (red balls are too big of a blob)\n",
    "    # NOTE: Hard-coded value\n",
    "    # KERNEL_BALL_SIZE = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20))\n",
    "    # green_close = cv2.morphologyEx(green_dilate, cv2.MORPH_CLOSE, KERNEL_BALL_SIZE)\n",
    "\n",
    "    # Get a thin edge of the green playing area\n",
    "    # NOTE: Hard-coded value\n",
    "    KERNEL_VERY_SMALL = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
    "    green_gradient = cv2.morphologyEx(\n",
    "        green_dilate, cv2.MORPH_GRADIENT, KERNEL_VERY_SMALL\n",
    "    )\n",
    "\n",
    "    # Intersect the green edge with the brown mask to obtain green/brow edges\n",
    "    edges_green_brown = cv2.bitwise_and(green_gradient, brown_dilate)\n",
    "\n",
    "    # # Draw edges in white\n",
    "    # edges_negative = cv2.bitwise_not(edges_green_brown)\n",
    "    # frame_BGR = cv2.bitwise_and(frame_BGR, frame_BGR, mask=edges_negative)\n",
    "    # frame_BGR = frame_BGR + cv2.cvtColor(edges_green_brown, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Compute lines that fit the edges\n",
    "    lines = hough_lines(edges_green_brown, num_lines=4)\n",
    "\n",
    "    # NOTE: order is important\n",
    "    l_top = lines[0]\n",
    "    l_bot = lines[1]\n",
    "    l_rig = lines[2]\n",
    "    l_lef = lines[3]\n",
    "\n",
    "    def A_b(rho1, theta1, rho2, theta2):\n",
    "        A = np.array(\n",
    "            [\n",
    "                [np.cos(theta1), np.sin(theta1)],\n",
    "                [np.cos(theta2), np.sin(theta2)],\n",
    "            ]\n",
    "        )\n",
    "        b = np.array([[rho1, rho2]]).T\n",
    "        return A, b\n",
    "\n",
    "    # find the intersection points\n",
    "    # $\\begin{bmatrix} \\cos\\theta_1 & \\sin\\theta_1 \\\\ \\cos\\theta_2 & \\sin\\theta_2 \\end{bmatrix} \\cdot \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} \\rho_1 \\\\ \\rho_2 \\end{bmatrix}$\n",
    "    top_left = np.linalg.solve(*A_b(*l_top, *l_lef)).T.squeeze()\n",
    "    top_right = np.linalg.solve(*A_b(*l_top, *l_rig)).T.squeeze()\n",
    "    bottom_left = np.linalg.solve(*A_b(*l_bot, *l_lef)).T.squeeze()\n",
    "    bottom_right = np.linalg.solve(*A_b(*l_bot, *l_rig)).T.squeeze()\n",
    "\n",
    "    return np.array(\n",
    "        [[top_left, top_right, bottom_right, bottom_left]],\n",
    "        dtype=np.int32,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad632d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_baulk_line(frame: MatLike) -> tuple:\n",
    "    \"\"\"\n",
    "    Function that detects the lines markings on the table\n",
    "    frame: BGR image\n",
    "    returns: baulk line in (rho, theta) format\n",
    "    \"\"\"\n",
    "    # Filter white color\n",
    "    white_HSL_low = np.array([9, 113, 2])  # Hardcoded white HSL value\n",
    "    brown_HSL_high = np.array([13, 128, 10])\n",
    "    frame_white = cv2.inRange(frame, white_HSL_low, brown_HSL_high)\n",
    "\n",
    "    baulk_line = hough_lines(frame_white, num_lines=1)\n",
    "\n",
    "    return baulk_line[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ball_centers(frame: MatLike) -> dict:\n",
    "    \"\"\"\n",
    "    frame: BGR image to detect the balls in\n",
    "    returns: dictionary of ball colors and their centers {color: [x, y], ...}\n",
    "    \"\"\"\n",
    "    img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # NOTE: Hard-coded values\n",
    "    ranges = {\n",
    "        \"yellow\": [20, 35],\n",
    "        \"brown\": [15, 23],\n",
    "        \"green\": [71, 85],\n",
    "        \"blue\": [85, 110],\n",
    "    }\n",
    "    KERNEL_BALL_SIZE = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8, 8))\n",
    "\n",
    "    centers = {}\n",
    "    for color, (lower, upper) in ranges.items():\n",
    "        ball = cv2.inRange(img_hsv[:, :, 0], np.array([lower]), np.array([upper]))\n",
    "        eroded = cv2.erode(ball, KERNEL_BALL_SIZE)\n",
    "        # get the average (middle) pixel x and y coordinate of the eroded ball\n",
    "        centers[color] = np.mean(np.argwhere(eroded != 0), axis=0, dtype=int)[::-1]\n",
    "\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f0c25c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# DLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2e68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_points_2D(points):\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    centered_points = points - centroid\n",
    "    mean_distance = np.mean(np.sqrt(np.sum(centered_points**2, axis=1)))\n",
    "    scale = np.sqrt(2) / mean_distance\n",
    "    T = np.array(\n",
    "        [[scale, 0, -scale * centroid[0]], [0, scale, -scale * centroid[1]], [0, 0, 1]]\n",
    "    )\n",
    "    normalized_points = (T @ np.hstack((points, np.ones((points.shape[0], 1)))).T).T\n",
    "    return normalized_points[:, :2], T\n",
    "\n",
    "\n",
    "def normalize_points_3D(points):\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    centered_points = points - centroid\n",
    "    mean_distance = np.mean(np.sqrt(np.sum(centered_points**2, axis=1)))\n",
    "    scale = np.sqrt(3) / mean_distance\n",
    "    T = np.array(\n",
    "        [\n",
    "            [scale, 0, 0, -scale * centroid[0]],\n",
    "            [0, scale, 0, -scale * centroid[1]],\n",
    "            [0, 0, scale, -scale * centroid[2]],\n",
    "            [0, 0, 0, 1],\n",
    "        ]\n",
    "    )\n",
    "    normalized_points = (T @ np.hstack((points, np.ones((points.shape[0], 1)))).T).T\n",
    "    return normalized_points[:, :3], T\n",
    "\n",
    "\n",
    "def DLT_normalized(X_in, x_in):\n",
    "    \"\"\"\n",
    "    Computes the Camera coordinates -> World coordinates matrix using normalized DLT alg\n",
    "    X: Points in 3D (world coordinates)\n",
    "    x: Corresponding points in 2D (camera coordinates)\n",
    "    \"\"\"\n",
    "    # Normalize the points\n",
    "    X_normalized, T_X = normalize_points_3D(X_in)\n",
    "    x_normalized, T_x = normalize_points_2D(x_in)\n",
    "\n",
    "    # Convert to homogeneous coordinates\n",
    "    X = np.hstack((X_normalized, np.ones((len(X_normalized), 1))))\n",
    "    x = np.hstack((x_normalized, np.ones((len(x_normalized), 1))))\n",
    "\n",
    "    # Building the matrix A that contains all correspondences\n",
    "    # relating them to the camera parameter vector p\n",
    "    A = np.empty((0, 12), int)\n",
    "    for i in range(len(X)):\n",
    "        x_i, y_i, w_i = x[i]\n",
    "        zeros = np.zeros((1, 4))\n",
    "        A_i = np.block(\n",
    "            [\n",
    "                [zeros, -w_i * X[i], y_i * X[i]],\n",
    "                [w_i * X[i], zeros, -x_i * X[i]],\n",
    "                [-y_i * X[i], x_i * X[i], zeros],\n",
    "            ]\n",
    "        )\n",
    "        A = np.vstack((A, A_i))\n",
    "\n",
    "    # Solving x = PX by computing single value decomposition of A\n",
    "    # It automatically deals with overdetermined system of equations\n",
    "    U, S, Vh = np.linalg.svd(A)\n",
    "    p = Vh[-1]\n",
    "    P_normalized = p.reshape(3, 4)\n",
    "\n",
    "    # Denormalize the projection matrix\n",
    "    P = np.linalg.inv(T_x) @ P_normalized @ T_X\n",
    "    P = P / P[-1, -1]\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ecee9",
   "metadata": {},
   "source": [
    "# Specular light detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d306a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# NOTE: Hard-coded vaues:\n",
    "# Colors of the balls\n",
    "COLORS = [\"blue\", \"red\", \"pink\", \"brown\", \"yellow\", \"green\", \"white\", \"black\"]\n",
    "COLOR_STR_TO_BGR = {\n",
    "    \"red\": (0, 0, 255),\n",
    "    \"blue\": (255, 0, 0),\n",
    "    \"pink\": (130, 130, 255),\n",
    "    \"green\": (0, 255, 0),\n",
    "    \"black\": (50, 50, 50),\n",
    "    \"brown\": (20, 70, 130),\n",
    "    \"yellow\": (0, 190, 250),\n",
    "}\n",
    "# Color of the blue ball\n",
    "MAX_BLUE = (25, 255, 255)\n",
    "MIN_BLUE = (10, 0, 30)\n",
    "# Color of the red balls\n",
    "MAX_RED = (130, 255, 190)\n",
    "MIN_RED = (110, 170, 0)\n",
    "# Color of the pink ball\n",
    "MAX_PINK = (130, 255, 255)\n",
    "MIN_PINK = (110, 0, 200)\n",
    "# Color of the brown ball\n",
    "MAX_BROWN = (110, 255, 150)\n",
    "MIN_BROWN = (90, 0, 0)\n",
    "# Color of the yellow ball\n",
    "MAX_YELLOW = (100, 255, 255)\n",
    "MIN_YELLOW = (90, 0, 150)\n",
    "# Color of the green ball\n",
    "MAX_GREEN = (50, 255, 255)\n",
    "MIN_GREEN = (30, 0, 0)\n",
    "# Color of the white ball\n",
    "MAX_WHITE = (90, 255, 255)\n",
    "MIN_WHITE = (70, 0, 150)\n",
    "# Color of the black ball\n",
    "MAX_BLACK = (255, 255, 50)\n",
    "MIN_BLACK = (0, 1, 0)\n",
    "# Color of the highlight/specular\n",
    "MIN_HIGHLIGHT = (0, 0, 245)\n",
    "# This value is used to detect the larger specular area so is more tolerant\n",
    "MAX_HIGHLIGHT_REGION = (255, 255, 255)\n",
    "MAX_HIGHLIGHT = (255, 120, 255)\n",
    "# Color of the highlight/specular on different balls:\n",
    "MIN_HIGHLIGHT_BLACK = (0, 0, 145)\n",
    "MAX_HIGHLIGHT_YELLOW = (255, 200, 255)\n",
    "MAX_HIGHLIGHT_PINK = (255, 70, 255)\n",
    "# Number of Iterations to erode the initial ball masks\n",
    "ERODE_ITERATIONS = 2\n",
    "ERODE_ITERATIONS_BLACK = 4\n",
    "# Number of Iterations to dilate the initial ball masks\n",
    "DILATE_ITERATIONS = 2\n",
    "\n",
    "\n",
    "def get_neighbours(point):\n",
    "    \"\"\"\n",
    "    Returns the neighbour coordinates of a pixel ignoring diagonals\n",
    "    \"\"\"\n",
    "    x, y = point\n",
    "    return [[x, y], [x + 1, y], [x - 1, y], [x, y + 1], [x, y - 1]]\n",
    "\n",
    "\n",
    "def merge_groups(groups, ignore_groups):\n",
    "    \"\"\"\n",
    "    Takes a list of lists containing coordinates of pixels.\n",
    "    These lists are called groups.\n",
    "    Merges 2 groups if they contain neighbouring pixels.\n",
    "    \"\"\"\n",
    "    ignore_groups = []  # ignore already processed groups to improve performance\n",
    "    for current_index, current_group in enumerate(groups):\n",
    "        if current_index in ignore_groups:\n",
    "            continue\n",
    "        for point in current_group:\n",
    "            neighbours = get_neighbours(point)\n",
    "            for index, group in enumerate(groups):\n",
    "                if index == current_index:\n",
    "                    continue\n",
    "                # check for every pixel if it has neighbours that belong to another group\n",
    "                exists = any(neighbour in group for neighbour in neighbours)\n",
    "                if exists:\n",
    "                    # merge the 2 groups\n",
    "                    groups[index] = groups[index] + groups[current_index]\n",
    "                    groups.pop(current_index)\n",
    "                    # print(\"merged\", index, current_index, \"=\", len(groups))\n",
    "                    return groups, True, ignore_groups\n",
    "        ignore_groups += [current_index]\n",
    "    return groups, False, ignore_groups\n",
    "\n",
    "\n",
    "def get_groups(mask, n=1):\n",
    "    \"\"\"\n",
    "    Given a mask, returns the n pargest patches/groups of pixels with value 255.\n",
    "    \"\"\"\n",
    "    # NOTE: Hard-coded value of the mask's value\n",
    "    candidates = np.where(mask == 255)\n",
    "\n",
    "    groups = []\n",
    "    for px, py in zip(candidates[0], candidates[1]):\n",
    "        added = False\n",
    "        neighbours = get_neighbours((px, py))\n",
    "        # check if the pixel belongs to an already created group\n",
    "        for index, group in enumerate(groups):\n",
    "            exists = any(elem in group for elem in neighbours)\n",
    "            if exists:\n",
    "                groups[index] = groups[index] + [[px, py]]\n",
    "                added = True\n",
    "        if not added:  # create new group\n",
    "            groups += [[[px, py]]]\n",
    "\n",
    "    # merge neighbouring groups, this is necessary as the previous step may have one patch into multiple groups\n",
    "    ignore_groups = []\n",
    "    merged = True\n",
    "    while merged:  # and len(groups)>n: # TODO is this robust without the n (if there are less than 15 red balls)?\n",
    "        groups, merged, ignore_groups = merge_groups(groups, ignore_groups)\n",
    "    groups = sorted(groups, key=len, reverse=True)\n",
    "    return groups\n",
    "\n",
    "\n",
    "def matches_window(frame, lower_mask, color_min_upper, color_max_upper):\n",
    "    \"\"\"\n",
    "    Checks for every pixel in a given mask if the above neighbour is withing a specified range.\n",
    "    Returns the coordinates of the upper pixels of such matchings.\n",
    "    \"\"\"\n",
    "    lower = lower_mask  # cv2.inRange(frame, color_min_lower, color_max_lower)\n",
    "    upper = cv2.inRange(frame, color_min_upper, color_max_upper)\n",
    "\n",
    "    lower_matched_x, lower_matched_y = np.where(lower == 255)\n",
    "\n",
    "    matchings = []\n",
    "    for lower_candidate_x, lower_candidate_y in zip(lower_matched_x, lower_matched_y):\n",
    "        if lower[lower_candidate_x, lower_candidate_y] > 0:\n",
    "            if upper[lower_candidate_x - 1, lower_candidate_y] == 255:\n",
    "                matchings.append((lower_candidate_x - 1, lower_candidate_y))\n",
    "        else:\n",
    "            print(\"image window out of bounds\")\n",
    "    return matchings\n",
    "\n",
    "\n",
    "def morphological_filter(group, dil_iter=0, ero_iter=0):\n",
    "    # remove duplicates (uncaught bug)\n",
    "    group.sort()\n",
    "    group = list(group for group, _ in itertools.groupby(group))\n",
    "\n",
    "    # Area filter\n",
    "\n",
    "    # create zero's matrix as background\n",
    "    ball_template = np.zeros((4 * dil_iter + 20, 4 * dil_iter + 20))\n",
    "\n",
    "    # insert template ball\n",
    "    ball_template[\n",
    "        2 * dil_iter : 2 * dil_iter + 20, 2 * dil_iter : 2 * dil_iter + 20\n",
    "    ] = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20))\n",
    "\n",
    "    ball_template = cv2.erode(ball_template, None, iterations=ero_iter)\n",
    "    ball_template = cv2.dilate(ball_template, None, iterations=dil_iter + ero_iter)\n",
    "    # img_show(ball_template*255)\n",
    "\n",
    "    area_ball = np.sum(ball_template)\n",
    "    # print(\"Area\", area_ball * 1.2, len(group))\n",
    "    if len(group) > area_ball * 1.2:\n",
    "        tmp = np.zeros((720, 1280))\n",
    "        for [x, y] in group:\n",
    "            if tmp[x, y] == 0:\n",
    "                tmp[x, y] = 255\n",
    "            else:\n",
    "                print(\"PANIK\")\n",
    "        img_show(tmp)\n",
    "        # print(\"Area fail\")\n",
    "        return False\n",
    "\n",
    "    # Bounding box (orthogonal diameter)\n",
    "    diameter_ball = 20 + 2 * dil_iter\n",
    "    group_x = [pixel[0] for pixel in group]\n",
    "    group_y = [pixel[1] for pixel in group]\n",
    "    diameter_x = np.max(group_x) - np.min(group_x)\n",
    "    diameter_y = np.max(group_y) - np.min(group_y)\n",
    "    diameter_group = max(diameter_x, diameter_y)\n",
    "    if diameter_group > diameter_ball * 1.2:\n",
    "        print(\"Diameter fail\")\n",
    "        return False\n",
    "    # print(\"Diameter\", diameter_ball, diameter_group)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def visualize_points(image, points, color):\n",
    "    \"\"\"\n",
    "    Takes an image and paints some points in specified color on top\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    image = np.zeros((image.shape[0], image.shape[1], 3))  # .astype(int)\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    for x, y in points:\n",
    "        image[x, y] = color\n",
    "    return image\n",
    "\n",
    "\n",
    "def detect_highlight(frame, version=\"max\"):\n",
    "    \"\"\"\n",
    "    Given a frame, returns the coordinates of the highlights/speculars on all balls.\n",
    "    Version=\"max\": returns the lower edge of the highlight\n",
    "    Version=\"mean\": returns the middle of the highlight\n",
    "    Return structure:\n",
    "    [(color_as_string, (x_coord, y_coord), mask_of_highlight), ...]\n",
    "    for red, the second element is a list of coordinates, as there may be multiple red balls:\n",
    "    [(x_coord_1, y_coord_1), (x_coord_2, y_coord_2), ...]\n",
    "    \"\"\"\n",
    "    # convert frame to HSV for easier color detection\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    mask_blue = cv2.inRange(hsv_frame, MIN_BLUE, MAX_BLUE)\n",
    "    mask_red = cv2.inRange(hsv_frame, MIN_RED, MAX_RED)\n",
    "    mask_pink = cv2.inRange(hsv_frame, MIN_PINK, MAX_PINK)\n",
    "    mask_brown = cv2.inRange(hsv_frame, MIN_BROWN, MAX_BROWN)\n",
    "    mask_yellow = cv2.inRange(hsv_frame, MIN_YELLOW, MAX_YELLOW)\n",
    "    mask_green = cv2.inRange(hsv_frame, MIN_GREEN, MAX_GREEN)\n",
    "    mask_white = cv2.inRange(hsv_frame, MIN_WHITE, MAX_WHITE)\n",
    "    mask_black = cv2.inRange(hsv_frame, MIN_BLACK, MAX_BLACK)\n",
    "\n",
    "    raw_masks = [\n",
    "        mask_blue,\n",
    "        mask_red,\n",
    "        mask_pink,\n",
    "        mask_brown,\n",
    "        mask_yellow,\n",
    "        mask_green,\n",
    "        mask_white,\n",
    "        mask_black,\n",
    "    ]\n",
    "    masks = []\n",
    "\n",
    "    # Dilate all masks and get largest patch:\n",
    "    for index, mask in enumerate(raw_masks):\n",
    "        erode_iterations = ERODE_ITERATIONS\n",
    "        dilate_iterations = DILATE_ITERATIONS\n",
    "        if index == 1:  # red\n",
    "            masks.append(mask)\n",
    "            continue  # Not parsing red as there are multiple red balls\n",
    "        if index == 7:  # black\n",
    "            erode_iterations = ERODE_ITERATIONS_BLACK\n",
    "        eroded_mask = cv2.erode(mask, None, iterations=erode_iterations)\n",
    "        dilated_mask = cv2.dilate(\n",
    "            eroded_mask, None, iterations=dilate_iterations + erode_iterations\n",
    "        )\n",
    "\n",
    "        groups = get_groups(dilated_mask, dilate_iterations - erode_iterations)\n",
    "\n",
    "        # Decapsulate\n",
    "        # Filter groups\n",
    "        groups = [\n",
    "            group\n",
    "            for group in groups\n",
    "            if morphological_filter(group, dilate_iterations, erode_iterations)\n",
    "        ]\n",
    "        if len(groups) == 0:\n",
    "            print(\"No ball found\")\n",
    "            continue\n",
    "        largest_group = groups[0]\n",
    "        new_mask = np.zeros(mask.shape)\n",
    "        for point in largest_group:\n",
    "            new_mask[point[0], point[1]] = 255\n",
    "        masks.append(new_mask)\n",
    "\n",
    "    highlight_masks = []\n",
    "\n",
    "    for mask in masks:\n",
    "        matchings = matches_window(\n",
    "            hsv_frame, mask, MIN_HIGHLIGHT_BLACK, MAX_HIGHLIGHT_REGION\n",
    "        )\n",
    "        matchings_visualized = visualize_points(mask, matchings, (0, 0, 255))\n",
    "        highlight_masks.append(matchings_visualized)\n",
    "        # cv2.imshow(\"matchings\", matchings_visualized)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "    highlight_masks_diluted = []\n",
    "    for index, highlight in enumerate(highlight_masks):\n",
    "        eroded_mask = cv2.erode(highlight, None, iterations=0)\n",
    "        dilated_mask = cv2.dilate(eroded_mask, None, iterations=4)\n",
    "        highlight_masks_diluted.append(dilated_mask)\n",
    "        # opacity = 0.2\n",
    "        # cv2.imshow(COLORS[index], cv2.addWeighted(frame.astype(np.uint8), opacity, dilated_mask.astype(np.uint8), 1, 0))\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "    results = []\n",
    "    for index, highlight in enumerate(highlight_masks_diluted):\n",
    "        # print(COLORS[index])\n",
    "        # search_mask = np.where(highlight[:, :, 2] != 255)\n",
    "        # at these locations, check the hsv frame for bright pixels\n",
    "\n",
    "        black_pixels = np.where(highlight[:, :, 2] != 255)\n",
    "        cropped_frame = hsv_frame.copy()\n",
    "        cropped_frame[black_pixels] = [0, 0, 0]\n",
    "\n",
    "        min_highlight = MIN_HIGHLIGHT\n",
    "        max_highlight = MAX_HIGHLIGHT\n",
    "        if COLORS[index] == \"black\":\n",
    "            min_highlight = MIN_HIGHLIGHT_BLACK\n",
    "        elif COLORS[index] == \"yellow\":\n",
    "            max_highlight = MAX_HIGHLIGHT_YELLOW\n",
    "        elif COLORS[index] == \"pink\":\n",
    "            max_highlight = MAX_HIGHLIGHT_PINK\n",
    "\n",
    "        highlight_pixels = cv2.inRange(cropped_frame, min_highlight, max_highlight)\n",
    "        high = cv2.cvtColor(highlight_pixels, cv2.COLOR_GRAY2BGR)\n",
    "        # img_show(np.concatenate((cropped_frame, high), axis=0))\n",
    "\n",
    "        highlight_coordinates = np.where(highlight_pixels > 0)\n",
    "\n",
    "        if len(highlight_coordinates[0]) == 0:\n",
    "            continue\n",
    "\n",
    "        if COLORS[index] == \"red\":\n",
    "            # get n biggest highlight\n",
    "            groups = get_groups(highlight_pixels)\n",
    "            largest_groups = groups[:15]\n",
    "            # get mean per group\n",
    "            # print(\"\\n\\n\\nred\")\n",
    "            highlight_mean = []\n",
    "            highlight_max = []\n",
    "            new_mask = np.zeros(highlight_pixels.shape)\n",
    "            for group in largest_groups:\n",
    "                group_mean = np.mean(group, axis=0)\n",
    "                highlight_mean.append(group_mean)\n",
    "                highlight_max.append(\n",
    "                    (np.max(np.array(group)[:, 0], axis=0), group_mean[1])\n",
    "                )\n",
    "                # print(COLORS[index], group_mean)\n",
    "                for point in group:\n",
    "                    new_mask[point[0], point[1]] = 255\n",
    "                    highlight_pixels = new_mask\n",
    "\n",
    "        else:\n",
    "            highlight_mean = np.mean(highlight_coordinates, axis=1)\n",
    "            highlight_max = [(max(highlight_coordinates[0]), highlight_mean[1])]\n",
    "\n",
    "            # print(COLORS[index], highlight_mean)\n",
    "        highlight_mean = np.array(highlight_mean)\n",
    "        if (\n",
    "            len(highlight_mean) > 1 and (highlight_mean == highlight_mean).all()\n",
    "        ):  # check that the mean is not NaN\n",
    "            if version == \"max\":\n",
    "                results.append((COLORS[index], highlight_max, highlight_pixels))\n",
    "            else:\n",
    "                results.append((COLORS[index], highlight_mean, highlight_pixels))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3267ca67",
   "metadata": {},
   "source": [
    "# Ball center from specular reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcfcb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ball_center_from_specular_reflection(P, Camera, Light, Specular_out):\n",
    "    P_inv = np.linalg.pinv(P)\n",
    "    balls_centers = []\n",
    "    for color, Specular_uv, mask_img in Specular_out:\n",
    "        balls_xyz = []\n",
    "        for ball_uv in Specular_uv:\n",
    "            Specular_homogeneus = np.append(ball_uv, [1])\n",
    "            # Camera coord of specular -> Camera line (multiply by inverse of P)\n",
    "            Specular_world_coord = P_inv.dot(Specular_homogeneus)\n",
    "            # Line from camera origin to Specular_i\n",
    "            Camera_line = {\n",
    "                \"origin\": Camera,\n",
    "                \"vector\": Specular_world_coord[:3] - Camera,  # vector b-a\n",
    "            }\n",
    "            # Normalize\n",
    "            Camera_line[\"vector\"] *= 1 / np.linalg.norm(Camera_line[\"vector\"])\n",
    "\n",
    "            # Solving inverse problem\n",
    "\n",
    "            # Distance of specular from camera origin (parameter lambda)\n",
    "            distance = Symbol(\"d\", real=True, positive=True)\n",
    "            # Equation of specular coordinates with respect to distance\n",
    "            Specular_xyz = Matrix(Camera_line[\"origin\"]) + distance * Matrix(\n",
    "                Camera_line[\"vector\"]\n",
    "            )\n",
    "            # Vector from specular to light source\n",
    "            light_vec = (Matrix(Light) - Specular_xyz).normalized()\n",
    "            # Normal vector at specular\n",
    "            normal_vec = (-Matrix(Camera_line[\"vector\"]) + light_vec).normalized()\n",
    "            # Ball center with respect to distance and radius\n",
    "            radius_ball = 0.02625  # in meters\n",
    "            Ball_xyz = Specular_xyz - normal_vec * radius_ball\n",
    "\n",
    "            # Solve for known height of ball center\n",
    "            f_z = Ball_xyz[2] - radius_ball\n",
    "            # and convert from sympy to scipy\n",
    "            f_z = lambdify(distance, f_z, \"scipy\")\n",
    "            # Use non-linear solver of scipy\n",
    "            distance_approx = fsolve(f_z, [1])  # Set initial guess to 1\n",
    "            # Use aproximation to compute coordinates of center\n",
    "            Ball_xyz = Camera_line[\"origin\"] + distance_approx * Camera_line[\"vector\"]\n",
    "            balls_xyz.append(Ball_xyz)\n",
    "\n",
    "        balls_centers.append((color, balls_xyz))\n",
    "\n",
    "    return balls_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114dc425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_balls(frame, ball_coordinates, scale, w_world, h_world):\n",
    "    \"\"\"Draws the balls on a given frame from world coordinates\"\"\"\n",
    "    radius = int(scale * 0.02625) + 1\n",
    "    scale *= 2\n",
    "    for color, coords in ball_coordinates:\n",
    "        for x, y, _ in coords:\n",
    "            x_c = int(scale * (-y - w_world / 2))\n",
    "            y_c = int(scale * 2 * (x + h_world / 4))\n",
    "            cv2.circle(\n",
    "                frame,\n",
    "                (x_c, y_c),\n",
    "                radius,\n",
    "                PALETTE[color],\n",
    "                thickness=-1,\n",
    "            )\n",
    "\n",
    "            # add a highlight and a shadow around the ball\n",
    "            overlay = frame.copy()\n",
    "            cv2.circle(\n",
    "                overlay,\n",
    "                (x_c, y_c),\n",
    "                radius,\n",
    "                PALETTE[\"black\"],\n",
    "                thickness=1,\n",
    "            )\n",
    "            cv2.circle(\n",
    "                overlay,\n",
    "                (x_c, y_c - 3),\n",
    "                1,\n",
    "                PALETTE[\"white\"],\n",
    "                thickness=-1,\n",
    "            )\n",
    "            frame = cv2.addWeighted(overlay, 0.75, frame, 0.25, 0)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42434154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_video(in_path: Path, out_path: Path, sample_tag: MatLike):\n",
    "    reader = VideoReader(in_path)\n",
    "\n",
    "    fps = reader.video.get(cv2.CAP_PROP_FPS)\n",
    "    shape = (\n",
    "        int(reader.video.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(reader.video.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "    )\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(str(out_path), fourcc, fps, shape)\n",
    "\n",
    "    # NOTE: scaling down the frame is slower (40s vs 36s for first 13mins)\n",
    "    for frame in reader:\n",
    "        frame_score_tag = extract_score_tag(frame)\n",
    "        if compare_score_tag(sample_tag, frame_score_tag, 0.05):\n",
    "            writer.write(frame)\n",
    "\n",
    "    writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3877e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PALETTE = {\n",
    "    \"black\": (40, 29, 21),\n",
    "    \"blue\": (186, 143, 79),\n",
    "    \"brown\": (44, 44, 96),\n",
    "    \"green\": (67, 167, 117),\n",
    "    \"pink\": (151, 81, 198),\n",
    "    \"red\": (48, 48, 165),\n",
    "    \"table\": (46, 86, 37),\n",
    "    \"white\": (233, 237, 235),\n",
    "    \"yellow\": (65, 158, 222),\n",
    "    \"red1\": (48, 48, 165),\n",
    "    \"red2\": (48, 48, 165),\n",
    "}\n",
    "\n",
    "\n",
    "data_path = Path(\"data\")\n",
    "ref_frame_path = str(data_path / \"WSC sample.png\")\n",
    "\n",
    "print(f\"Processing {ref_frame_path}...\")\n",
    "reference_frame = cv2.imread(ref_frame_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Find table boundaries and create a mask to hide irrelevant frame data\n",
    "corners = table_edges_detection(reference_frame.copy())\n",
    "mask = cv2.fillPoly(np.zeros(reference_frame.shape[:2], dtype=np.uint8), corners, 1)\n",
    "\n",
    "# Show the selected area\n",
    "mask_neg = cv2.fillPoly(\n",
    "    np.ones(reference_frame.shape[:2], dtype=np.uint8), corners, 0\n",
    ")\n",
    "reference_frame_neg = cv2.bitwise_and(\n",
    "    reference_frame, reference_frame, mask=mask_neg\n",
    ")\n",
    "# img_show(reference_frame_neg)\n",
    "\n",
    "# apply the mask\n",
    "masked_frame = cv2.bitwise_and(reference_frame, reference_frame, mask=mask)\n",
    "# img_show(masked_frame)\n",
    "\n",
    "# Find reference points (ball centers and baulk line)\n",
    "centers = get_ball_centers(masked_frame)\n",
    "(baulk_rho, baulk_theta) = detect_baulk_line(masked_frame)\n",
    "\n",
    "# Calculate the coordinates where the balls are placed on the table\n",
    "ground_points = {}\n",
    "for color, (x, _) in centers.items():\n",
    "    if color not in [\"yellow\", \"brown\", \"green\"]:\n",
    "        continue\n",
    "\n",
    "    # $y = \\frac{\\rho - x\\cos\\theta}{\\sin\\theta}$\n",
    "    y = (baulk_rho - x * np.cos(baulk_theta)) / np.sin(baulk_theta)\n",
    "    ground_points[color + \"_table\"] = [x, int(y)]\n",
    "\n",
    "image_points = centers | ground_points\n",
    "\n",
    "x_points = np.array(\n",
    "    [\n",
    "        image_points[\"yellow\"],\n",
    "        image_points[\"yellow_table\"],\n",
    "        image_points[\"brown\"],\n",
    "        image_points[\"brown_table\"],\n",
    "        image_points[\"green\"],\n",
    "        image_points[\"green_table\"],\n",
    "        image_points[\"blue\"],\n",
    "        # play area corners\n",
    "        *corners[0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# http://www.fcsnooker.co.uk/billiards/the_table_and%20table_markings.htm\n",
    "# we are detecting the play area +2 inches for the cushions\n",
    "X_points = np.array(\n",
    "    [\n",
    "        # balls\n",
    "        [-0.292, 1.0475, 0.02625],  # yellow\n",
    "        [-0.292, 1.0475, 0.0],  # yellow_table\n",
    "        [0.0, 1.0475, 0.02625],  # brown\n",
    "        [0.0, 1.0475, 0.0],  # brown_table\n",
    "        [0.292, 1.0475, 0.02625],  # green\n",
    "        [0.292, 1.0475, 0.0],  # green_table\n",
    "        [0.0, 0.0, 0.02625],  # blue\n",
    "        # play area + cushions corners\n",
    "        [-0.934, 1.829, 0.03],  # top-left\n",
    "        [0.934, 1.829, 0.03],  # top-right\n",
    "        [0.934, -1.829, 0.03],  # bottom-right\n",
    "        [-0.934, -1.829, 0.03],  # bottom-left\n",
    "    ]\n",
    ")\n",
    "\n",
    "# DLT\n",
    "P = DLT_normalized(X_points, x_points)\n",
    "# P = DLT(X_points, x_points)\n",
    "M = P[:, :3]  # Rotation matrix of the camera\n",
    "camera = -np.linalg.inv(M).dot(P[:, 3].transpose())\n",
    "\n",
    "LIGHT_HARDCODED = [-3, 0, 6]\n",
    "\n",
    "# for _, (x, y) in image_points.items():\n",
    "#     reference_frame[y, x] = (0, 0, 255)\n",
    "# img_show(reference_frame, \"with centers\")\n",
    "\n",
    "# Video processing\n",
    "video_path = data_path / \"WSC.mp4\"\n",
    "\n",
    "filtered_path = video_path.with_name(\n",
    "    video_path.stem + \"_filtered\" + video_path.suffix\n",
    ")\n",
    "\n",
    "# Create a filtered video if it doesn't exist (might take ~15mins)\n",
    "if not filtered_path.exists():\n",
    "    sample_score_tag = extract_score_tag(reference_frame)\n",
    "    filter_video(video_path, filtered_path, sample_score_tag)\n",
    "\n",
    "# Prep rendering\n",
    "w_world = 1.868\n",
    "h_world = 3.658\n",
    "h_img = reference_frame.shape[0]\n",
    "scale = h_img / h_world\n",
    "w_img = int(scale * w_world)\n",
    "table = np.full((h_img, w_img, 3), PALETTE[\"table\"], dtype=np.uint8)\n",
    "\n",
    "baulk_line = int(scale * (-1.0475 + h_world / 2))\n",
    "table[baulk_line] = PALETTE[\"white\"]\n",
    "\n",
    "reader = VideoReader(filtered_path, max_count=10_000)\n",
    "\n",
    "fps = reader.video.get(cv2.CAP_PROP_FPS)\n",
    "shape = (\n",
    "    int(reader.video.get(cv2.CAP_PROP_FRAME_WIDTH) + w_img),\n",
    "    int(reader.video.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    ")\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "writer = cv2.VideoWriter(str(data_path / \"result.mp4\"), fourcc, fps, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b31af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in reader:\n",
    "    masked_frame = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    specular_out = detect_highlight(masked_frame)\n",
    "\n",
    "    res = compute_ball_center_from_specular_reflection(\n",
    "        P, camera, LIGHT_HARDCODED, specular_out\n",
    "    )\n",
    "\n",
    "    table_frame = draw_balls(table.copy(), res, scale, w_world, h_world)\n",
    "\n",
    "    # display result\n",
    "    display = np.concatenate((masked_frame, table_frame), axis=1)\n",
    "    writer.write(display)\n",
    "    print(\"writing...\")\n",
    "\n",
    "    # cv2.imshow(\"Video\", display)\n",
    "    # # window closing\n",
    "    # key = cv2.waitKey(10)\n",
    "    # if (\n",
    "    #     cv2.getWindowProperty(\"Video\", cv2.WND_PROP_VISIBLE) < 1  # window is closed\n",
    "    #     or (key & 0xFF) == ord(\"q\")\n",
    "    # ):\n",
    "    #     cv2.destroyAllWindows()\n",
    "    #     break\n",
    "\n",
    "writer.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
